{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np\n",
    "import  random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LSTM Language Models Trained with Log Loss (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 1498\n"
     ]
    }
   ],
   "source": [
    "B= 32\n",
    "def dataset_preparation(data):\n",
    "    corpus = data.split(\"\\n\")\n",
    "    \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        input_sequences.append(token_list)\n",
    "    max_sequence_len= 22\n",
    "    k = B- (len(input_sequences) % B)\n",
    "    for i in range(k):\n",
    "        input_sequences.append(np.zeros(len(input_sequences[-1])))\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='post'))\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,1:].copy()\n",
    "    for i in range(predictors.shape[0]):\n",
    "        for j in range(predictors.shape[1]):\n",
    "            if predictors[i][j] == 2:\n",
    "                predictors[i][j] = 0\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "tokenizer = Tokenizer(lower=False,filters='')\n",
    "data = open('bobsue.voc.txt').read()\n",
    "corpus = data.split(\"\\n\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)\n",
    "print(\"total words: \",end=\"\")\n",
    "print(total_words)\n",
    "\n",
    "data = open('bobsue.lm.train.txt').read()\n",
    "dev_data = open('bobsue.lm.dev.txt').read()\n",
    "test_data = open('bobsue.lm.test.txt').read()\n",
    "predictors, label, max_sequence_len = dataset_preparation(data)\n",
    "d_predictors, d_label, max_sequence_len = dataset_preparation(dev_data)\n",
    "t_predictors, t_label, t_max_sequence_len = dataset_preparation(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 LSTM Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label, X_val,Y_val, max_sequence_len, total_words):\n",
    "    model = Sequential()\n",
    "    #mask_zero to neglect padding during training  \n",
    "    model.add(Embedding(total_words, 200, input_length=max_sequence_len-1,mask_zero=True))\n",
    "    model.add(LSTM(200,return_sequences=True)) \n",
    "\n",
    "    model.add(Dense(total_words))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    model.fit(predictors, label, epochs=10, batch_size=B,validation_data=(X_val, Y_val),verbose=1, callbacks=[earlystop])\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Training and Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/10\n",
      "6048/6048 [==============================] - 17s 3ms/step - loss: 5.1881 - categorical_accuracy: 0.1862 - val_loss: 4.4424 - val_categorical_accuracy: 0.2400\n",
      "Epoch 2/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 4.2688 - categorical_accuracy: 0.2472 - val_loss: 4.0577 - val_categorical_accuracy: 0.2713\n",
      "Epoch 3/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.9355 - categorical_accuracy: 0.2776 - val_loss: 3.8253 - val_categorical_accuracy: 0.2931\n",
      "Epoch 4/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.7343 - categorical_accuracy: 0.2929 - val_loss: 3.7044 - val_categorical_accuracy: 0.3004\n",
      "Epoch 5/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.6030 - categorical_accuracy: 0.3029 - val_loss: 3.6243 - val_categorical_accuracy: 0.3083\n",
      "Epoch 6/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.4970 - categorical_accuracy: 0.3120 - val_loss: 3.5660 - val_categorical_accuracy: 0.3122\n",
      "Epoch 7/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.4114 - categorical_accuracy: 0.3194 - val_loss: 3.5207 - val_categorical_accuracy: 0.3089\n",
      "Epoch 8/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.3349 - categorical_accuracy: 0.3251 - val_loss: 3.4883 - val_categorical_accuracy: 0.3203\n",
      "Epoch 9/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.2663 - categorical_accuracy: 0.3302 - val_loss: 3.4682 - val_categorical_accuracy: 0.3265\n",
      "Epoch 10/10\n",
      "6048/6048 [==============================] - 7s 1ms/step - loss: 3.2050 - categorical_accuracy: 0.3360 - val_loss: 3.4494 - val_categorical_accuracy: 0.3236\n"
     ]
    }
   ],
   "source": [
    "model = create_model(predictors, label,d_predictors, d_label, max_sequence_len, total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Error Analysis (15 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total predictions: 8059\n",
      "accuracy: 0.31666459858543244\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model,p ,t):\n",
    "    #Manually implement a evaluate to check test accuracym, so that we can make sure num of predictions is correct\n",
    "    total = 0 \n",
    "    k = model.predict(p)\n",
    "    k = list(k)\n",
    "    for i in range(len(k)):\n",
    "        k[i] = k[i].argmax(axis=1)\n",
    "    k = np.array(k)\n",
    "    m = t.argmax(axis=2)\n",
    "    correct = 0\n",
    "    err_count = {}\n",
    "    for i in range(k.shape[0]):\n",
    "        for j in range(k.shape[1]):\n",
    "            #if label is neither padding nor <s>\n",
    "            if m[i][j] != 0 and m[i][j] != 1 : \n",
    "                total+=1 \n",
    "                if k[i][j] == m[i][j]:\n",
    "                    correct+=1 \n",
    "                else: \n",
    "                    if (m[i][j],k[i][j]) in err_count:\n",
    "                        err_count[(m[i][j],k[i][j])] +=1\n",
    "                    else:\n",
    "                        err_count[(m[i][j],k[i][j])] =1\n",
    "                        \n",
    "    return total,correct/total,err_count\n",
    "\n",
    "\n",
    "total,acc,err_count = evaluate(model,t_predictors,t_label)\n",
    "print(\"total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Top 35 most frequent errors with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Top 35 Error----\n",
      "First item of pair is truth, second item is prediction\n",
      "('He', 'Bob') Count: 136\n",
      "('She', 'Bob') Count: 112\n",
      "('Sue', 'Bob') Count: 106\n",
      "('to', '.') Count: 51\n",
      "('had', 'was') Count: 48\n",
      "('decided', 'was') Count: 45\n",
      "('his', 'the') Count: 43\n",
      "('and', '.') Count: 42\n",
      "('her', 'the') Count: 38\n",
      "('in', '.') Count: 34\n",
      "('for', '.') Count: 33\n",
      "('her', 'a') Count: 28\n",
      "('she', 'he') Count: 28\n",
      "(',', '.') Count: 28\n",
      "('His', 'Bob') Count: 27\n",
      "('.', 'to') Count: 27\n",
      "('got', 'was') Count: 26\n",
      "('the', 'a') Count: 25\n",
      "('.', 'and') Count: 25\n",
      "('One', 'Bob') Count: 25\n",
      "('a', 'the') Count: 23\n",
      "('a', 'to') Count: 23\n",
      "('The', 'Bob') Count: 23\n",
      "('it', 'the') Count: 22\n",
      "('But', 'Bob') Count: 21\n",
      "('Her', 'Bob') Count: 21\n",
      "(\"'s\", 'was') Count: 20\n",
      "('!', '.') Count: 20\n",
      "('wanted', 'was') Count: 20\n",
      "('went', 'was') Count: 20\n",
      "('When', 'Bob') Count: 19\n",
      "('They', 'Bob') Count: 19\n",
      "('the', '.') Count: 19\n",
      "('he', 'Bob') Count: 18\n",
      "('for', 'to') Count: 18\n"
     ]
    }
   ],
   "source": [
    "sort_err = sorted(err_count.items(),key=lambda x:x[1],reverse=True)\n",
    "def translate(a):\n",
    "    x,y = a \n",
    "    return (tokenizer.index_word[x],tokenizer.index_word[y])\n",
    "top35 = sort_err[0:35]\n",
    "\n",
    "print(\"----Top 35 Error----\")\n",
    "print(\"First item of pair is truth, second item is prediction\")\n",
    "\n",
    "for t,cnt in top35:\n",
    "    true, pred = translate(t)\n",
    "    print((true,pred),end=\" \")\n",
    "    print(\"Count: \",end=\"\")\n",
    "    print(cnt)\n",
    "#Answer to 2.3 See Latex file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary Log Loss Implementation and Experimentation (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementation of Binary Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import keras\n",
    "\n",
    "\n",
    "B = 32\n",
    "def custom_gather(a, b):\n",
    "    unstacked_a = tf.unstack(a, axis=0)\n",
    "    unstacked_b = tf.unstack(b, axis=0)\n",
    "    gathered = [tf.gather(x, y) for x, y in zip(unstacked_a, unstacked_b)]\n",
    "    return tf.stack(gathered, axis=0)\n",
    "\n",
    "\n",
    "def bin_loss(r):\n",
    "    def _bin_loss(y_true, y_pred):\n",
    "        #Binary Log loss\n",
    "        d = B*21    \n",
    "        index = [i for i in range(total_words)]\n",
    "        NEG = np.zeros((r,total_words))\n",
    "        u_prob = np.array(total_words*[1])\n",
    "        u_prob = u_prob/sum(u_prob)\n",
    "        for i in range(total_words):\n",
    "            temp = u_prob.copy()\n",
    "            NEG[:,i]= np.random.choice(index,r,p=temp) + 1\n",
    "        neg= tf.cast(tf.convert_to_tensor(NEG),tf.int32)\n",
    "        y_true = K.reshape(y_true,(d,total_words))\n",
    "\n",
    "        y_true2 = K.cast(y_true,tf.int32)\n",
    "        y_pred = K.reshape(y_pred,(d,total_words))\n",
    "        MASK = K.batch_dot(y_true2,mask,axes=1)\n",
    "        MASK = K.cast(MASK,tf.float32)\n",
    "        good_loss = -K.dot(K.transpose(K.log(K.sigmoid(K.batch_dot(y_pred,y_true,axes=1)))),MASK)\n",
    "\n",
    "        slices = K.dot(y_true2,K.transpose(neg))\n",
    "        bad = custom_gather(y_pred,slices)\n",
    "        bad_loss = K.log(K.ones(shape=(d, r)) - K.sigmoid(bad))\n",
    "\n",
    "        MASK = K.repeat_elements(MASK,rep=r,axis=1)\n",
    "        bad_loss = K.batch_dot(bad_loss,MASK,axes=1)\n",
    "        loss =(good_loss-K.sum(bad_loss)/r)\n",
    "        return loss\n",
    "    return _bin_loss\n",
    "\n",
    "#I used bias at scoring function\n",
    "def create_model2(predictors, label,X_val, Y_val, max_sequence_len, total_words,f):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 200, input_length=max_sequence_len-1,mask_zero=True))\n",
    "    model.add(LSTM(200,return_sequences=True)) \n",
    "    model.add(Dense(total_words,use_bias=True))\n",
    "    model.compile(loss=f, optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "    model.fit(predictors, label, epochs=20, batch_size=B,validation_data=(X_val, Y_val),verbose=1, callbacks=[earlystop])\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 UNIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "6048/6048 [==============================] - 38s 6ms/step - loss: 271.4413 - categorical_accuracy: 0.0668 - val_loss: 221.4719 - val_categorical_accuracy: 0.1165\n",
      "Epoch 2/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 224.2945 - categorical_accuracy: 0.1103 - val_loss: 202.8100 - val_categorical_accuracy: 0.1165\n",
      "Epoch 3/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 209.6999 - categorical_accuracy: 0.1155 - val_loss: 193.9695 - val_categorical_accuracy: 0.1383\n",
      "Epoch 4/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 201.2975 - categorical_accuracy: 0.1257 - val_loss: 187.5862 - val_categorical_accuracy: 0.1468\n",
      "Epoch 5/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 192.8786 - categorical_accuracy: 0.1687 - val_loss: 177.9709 - val_categorical_accuracy: 0.1966\n",
      "Epoch 6/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 181.3626 - categorical_accuracy: 0.1994 - val_loss: 168.6554 - val_categorical_accuracy: 0.2010\n",
      "Epoch 7/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 171.2555 - categorical_accuracy: 0.2002 - val_loss: 160.7046 - val_categorical_accuracy: 0.2004\n",
      "Epoch 8/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 162.1772 - categorical_accuracy: 0.1953 - val_loss: 154.3986 - val_categorical_accuracy: 0.2057\n",
      "Epoch 9/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 154.3472 - categorical_accuracy: 0.1994 - val_loss: 148.8811 - val_categorical_accuracy: 0.2006\n",
      "Epoch 10/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 147.3928 - categorical_accuracy: 0.1980 - val_loss: 144.1323 - val_categorical_accuracy: 0.1906\n",
      "Epoch 11/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 141.0901 - categorical_accuracy: 0.1944 - val_loss: 140.1757 - val_categorical_accuracy: 0.2053\n",
      "Epoch 12/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 135.5260 - categorical_accuracy: 0.2001 - val_loss: 136.7059 - val_categorical_accuracy: 0.2004\n",
      "Epoch 13/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 130.3377 - categorical_accuracy: 0.2030 - val_loss: 133.7318 - val_categorical_accuracy: 0.1974\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "#With some experiment, It turns out SGD is better for r=20 case than adam\n",
    "def create_model2(predictors, label,X_val, Y_val, max_sequence_len, total_words,f):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 200, input_length=max_sequence_len-1,mask_zero=True))\n",
    "    model.add(LSTM(200,return_sequences=True)) \n",
    "    model.add(Dense(total_words,use_bias=True))\n",
    "    model.compile(loss=f, optimizer='SGD', metrics=['categorical_accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "    model.fit(predictors, label, epochs=20, batch_size=B,validation_data=(X_val, Y_val),verbose=1, callbacks=[earlystop])\n",
    "    \n",
    "    return model \n",
    "# Sample 20 words uniformaly\n",
    "r = 20\n",
    "mask = np.ones((B*21,total_words))\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i][0] = 0\n",
    "mask1 = mask\n",
    "mask= tf.cast(tf.convert_to_tensor(mask1),tf.int32)\n",
    "model2_20 = create_model2(predictors, label,d_predictors, d_label, max_sequence_len, total_words,bin_loss(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "6048/6048 [==============================] - 40s 7ms/step - loss: 282.8759 - categorical_accuracy: 0.1075 - val_loss: 213.7226 - val_categorical_accuracy: 0.1134\n",
      "Epoch 2/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 202.6972 - categorical_accuracy: 0.1068 - val_loss: 179.0679 - val_categorical_accuracy: 0.1217\n",
      "Epoch 3/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 173.0205 - categorical_accuracy: 0.1107 - val_loss: 162.1729 - val_categorical_accuracy: 0.1118\n",
      "Epoch 4/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 155.2044 - categorical_accuracy: 0.1142 - val_loss: 152.8561 - val_categorical_accuracy: 0.1350\n",
      "Epoch 5/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 141.9762 - categorical_accuracy: 0.1366 - val_loss: 147.0392 - val_categorical_accuracy: 0.1623\n",
      "Epoch 6/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 131.3371 - categorical_accuracy: 0.1810 - val_loss: 143.2009 - val_categorical_accuracy: 0.2080\n",
      "Epoch 7/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 122.4325 - categorical_accuracy: 0.2097 - val_loss: 140.7323 - val_categorical_accuracy: 0.2188\n",
      "Epoch 8/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 114.8453 - categorical_accuracy: 0.2229 - val_loss: 138.3282 - val_categorical_accuracy: 0.2303\n",
      "Epoch 9/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 108.0806 - categorical_accuracy: 0.2336 - val_loss: 138.0169 - val_categorical_accuracy: 0.2363\n",
      "Epoch 10/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 102.2782 - categorical_accuracy: 0.2392 - val_loss: 138.4829 - val_categorical_accuracy: 0.2417\n",
      "Epoch 11/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 96.8008 - categorical_accuracy: 0.2427 - val_loss: 138.2822 - val_categorical_accuracy: 0.2403\n",
      "Epoch 12/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 92.0636 - categorical_accuracy: 0.2471 - val_loss: 139.3605 - val_categorical_accuracy: 0.2525\n",
      "Epoch 13/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 87.7706 - categorical_accuracy: 0.2503 - val_loss: 139.5701 - val_categorical_accuracy: 0.2550\n",
      "Epoch 14/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 83.7615 - categorical_accuracy: 0.2513 - val_loss: 141.4627 - val_categorical_accuracy: 0.2592\n",
      "Epoch 15/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 80.0748 - categorical_accuracy: 0.2518 - val_loss: 143.5802 - val_categorical_accuracy: 0.2505\n",
      "Epoch 16/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 76.7250 - categorical_accuracy: 0.2540 - val_loss: 146.1321 - val_categorical_accuracy: 0.2488\n",
      "Epoch 17/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 73.5975 - categorical_accuracy: 0.2526 - val_loss: 146.8040 - val_categorical_accuracy: 0.2580\n",
      "Epoch 18/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 70.6076 - categorical_accuracy: 0.2516 - val_loss: 150.2240 - val_categorical_accuracy: 0.2423\n",
      "Epoch 19/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 67.8991 - categorical_accuracy: 0.2522 - val_loss: 153.1145 - val_categorical_accuracy: 0.2637\n",
      "Epoch 20/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 65.4156 - categorical_accuracy: 0.2536 - val_loss: 155.6625 - val_categorical_accuracy: 0.2603\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 words uniformaly\n",
    "r = 100\n",
    "mask = np.ones((B*21,total_words))\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i][0] = 0\n",
    "mask1 = mask\n",
    "mask= tf.cast(tf.convert_to_tensor(mask1),tf.int32)\n",
    "model2_100 = create_model2(predictors, label,d_predictors, d_label, max_sequence_len, total_words,bin_loss(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "6048/6048 [==============================] - 42s 7ms/step - loss: 293.2980 - categorical_accuracy: 0.1041 - val_loss: 229.6964 - val_categorical_accuracy: 0.1222\n",
      "Epoch 2/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 217.2696 - categorical_accuracy: 0.1231 - val_loss: 189.3954 - val_categorical_accuracy: 0.1371\n",
      "Epoch 3/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 181.6837 - categorical_accuracy: 0.1392 - val_loss: 169.0673 - val_categorical_accuracy: 0.1654\n",
      "Epoch 4/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 160.4339 - categorical_accuracy: 0.2270 - val_loss: 158.5487 - val_categorical_accuracy: 0.2404\n",
      "Epoch 5/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 145.5129 - categorical_accuracy: 0.2386 - val_loss: 151.8848 - val_categorical_accuracy: 0.2478\n",
      "Epoch 6/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 133.9477 - categorical_accuracy: 0.2488 - val_loss: 147.5676 - val_categorical_accuracy: 0.2554\n",
      "Epoch 7/20\n",
      "6048/6048 [==============================] - 26s 4ms/step - loss: 124.5979 - categorical_accuracy: 0.2558 - val_loss: 145.0681 - val_categorical_accuracy: 0.2659\n",
      "Epoch 8/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 116.9127 - categorical_accuracy: 0.2615 - val_loss: 143.5432 - val_categorical_accuracy: 0.2662\n",
      "Epoch 9/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 110.3216 - categorical_accuracy: 0.2639 - val_loss: 143.8433 - val_categorical_accuracy: 0.2709\n",
      "Epoch 10/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 104.5923 - categorical_accuracy: 0.2668 - val_loss: 143.6777 - val_categorical_accuracy: 0.2729\n",
      "Epoch 11/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 99.4679 - categorical_accuracy: 0.2686 - val_loss: 144.4612 - val_categorical_accuracy: 0.2631\n",
      "Epoch 12/20\n",
      "6048/6048 [==============================] - 24s 4ms/step - loss: 94.8216 - categorical_accuracy: 0.2706 - val_loss: 145.2315 - val_categorical_accuracy: 0.2758\n",
      "Epoch 13/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 90.6901 - categorical_accuracy: 0.2718 - val_loss: 146.6728 - val_categorical_accuracy: 0.2789\n",
      "Epoch 14/20\n",
      "6048/6048 [==============================] - 24s 4ms/step - loss: 86.8403 - categorical_accuracy: 0.2747 - val_loss: 148.9353 - val_categorical_accuracy: 0.2791\n",
      "Epoch 15/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 83.2935 - categorical_accuracy: 0.2755 - val_loss: 151.4339 - val_categorical_accuracy: 0.2826\n",
      "Epoch 16/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 80.0610 - categorical_accuracy: 0.2767 - val_loss: 153.0997 - val_categorical_accuracy: 0.2815\n",
      "Epoch 17/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 76.9653 - categorical_accuracy: 0.2783 - val_loss: 156.3934 - val_categorical_accuracy: 0.2844\n",
      "Epoch 18/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 74.0731 - categorical_accuracy: 0.2792 - val_loss: 158.6621 - val_categorical_accuracy: 0.2843\n",
      "Epoch 19/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 71.4700 - categorical_accuracy: 0.2802 - val_loss: 161.9986 - val_categorical_accuracy: 0.2835\n",
      "Epoch 20/20\n",
      "6048/6048 [==============================] - 25s 4ms/step - loss: 68.9039 - categorical_accuracy: 0.2811 - val_loss: 164.8598 - val_categorical_accuracy: 0.2838\n"
     ]
    }
   ],
   "source": [
    "# Sample 500 words uniformaly\n",
    "r = 500\n",
    "mask = np.ones((B*21,total_words))\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i][0] = 0\n",
    "mask1 = mask\n",
    "mask= tf.cast(tf.convert_to_tensor(mask1),tf.int32)\n",
    "model2_500 = create_model2(predictors, label,d_predictors, d_label, max_sequence_len, total_words,bin_loss(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 500, total predictions: 8059\n",
      "accuracy: 0.28216900359846137\n",
      "r = 100, total predictions: 8059\n",
      "accuracy: 0.2543739918103983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total,acc,err_count = evaluate(model2_500,t_predictors,t_label)\n",
    "print(\"r = 500, total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)\n",
    "total,acc,err_count = evaluate(model2_100,t_predictors,t_label)\n",
    "print(\"r = 100, total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 20, total predictions: 8059\n",
      "accuracy: 0.19779128924184142\n"
     ]
    }
   ],
   "source": [
    "total,acc,err_count = evaluate(model2_20,t_predictors,t_label)\n",
    "print(\"r = 20, total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 UNIG-F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_loss_unig(r,u_prob):\n",
    "    def _bin_loss_unig(y_true, y_pred):\n",
    "        #Binary Log loss\n",
    "        d = B*21    \n",
    "        index = [i for i in range(total_words)]\n",
    "        NEG = np.zeros((r,total_words))\n",
    "        for i in range(total_words):\n",
    "            temp = u_prob.copy()\n",
    "            temp = temp/sum(temp)\n",
    "            NEG[:,i]= np.random.choice(index,r,p=temp) + 1\n",
    "            \n",
    "        neg= tf.cast(tf.convert_to_tensor(NEG),tf.int32)\n",
    "        \n",
    "        y_true = K.reshape(y_true,(d,total_words))\n",
    "\n",
    "        y_true2 = K.cast(y_true,tf.int32)\n",
    "        y_pred = K.reshape(y_pred,(d,total_words))\n",
    "        MASK = K.batch_dot(y_true2,mask,axes=1)\n",
    "        MASK = K.cast(MASK,tf.float32)\n",
    "        good_loss = -K.dot(K.transpose(K.log(K.sigmoid(K.batch_dot(y_pred,y_true,axes=1)))),MASK)\n",
    "\n",
    "        slices = K.dot(y_true2,K.transpose(neg))\n",
    "        bad = custom_gather(y_pred,slices)\n",
    "        bad_loss = K.log(K.ones(shape=(d, r)) - K.sigmoid(bad))\n",
    "\n",
    "        MASK = K.repeat_elements(MASK,rep=r,axis=1)\n",
    "        bad_loss = K.batch_dot(bad_loss,MASK,axes=1)\n",
    "        loss =(good_loss-K.sum(bad_loss)/r)\n",
    "    \n",
    "        return loss\n",
    "    return _bin_loss_unig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.zeros(1498)\n",
    "corpus = data.split(\"\\n\")\n",
    "total = 0 \n",
    "for i in corpus:\n",
    "    k = i.split(\" \")\n",
    "    for w in k:\n",
    "        if w != \"<s>\":\n",
    "            total += 1 \n",
    "            prob[tokenizer.word_index[w] - 1] =  prob[tokenizer.word_index[w] - 1] + 1\n",
    "prob = prob / total\n",
    "\n",
    "def unig_f(p,f):\n",
    "    p = np.power(p,f)\n",
    "    arr1 = p / sum(p)\n",
    "    return arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "6048/6048 [==============================] - 42s 7ms/step - loss: 325.0563 - categorical_accuracy: 0.1082 - val_loss: 241.1752 - val_categorical_accuracy: 0.1075\n",
      "Epoch 2/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 224.0729 - categorical_accuracy: 0.1154 - val_loss: 192.4460 - val_categorical_accuracy: 0.1202\n",
      "Epoch 3/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 186.4034 - categorical_accuracy: 0.1149 - val_loss: 171.7320 - val_categorical_accuracy: 0.1165\n",
      "Epoch 4/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 163.0630 - categorical_accuracy: 0.1139 - val_loss: 158.8878 - val_categorical_accuracy: 0.0993\n",
      "Epoch 5/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 146.2194 - categorical_accuracy: 0.1220 - val_loss: 151.7685 - val_categorical_accuracy: 0.1327\n",
      "Epoch 6/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 133.9837 - categorical_accuracy: 0.1244 - val_loss: 147.4939 - val_categorical_accuracy: 0.1491\n",
      "Epoch 7/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 124.6384 - categorical_accuracy: 0.1546 - val_loss: 145.2426 - val_categorical_accuracy: 0.1715\n",
      "Epoch 8/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 116.9437 - categorical_accuracy: 0.1541 - val_loss: 144.3320 - val_categorical_accuracy: 0.1425\n",
      "Epoch 9/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 110.4094 - categorical_accuracy: 0.1634 - val_loss: 143.7620 - val_categorical_accuracy: 0.1606\n",
      "Epoch 10/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 104.8189 - categorical_accuracy: 0.1731 - val_loss: 144.2053 - val_categorical_accuracy: 0.1599\n",
      "Epoch 11/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 99.8418 - categorical_accuracy: 0.1794 - val_loss: 144.9722 - val_categorical_accuracy: 0.1538\n",
      "Epoch 12/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 95.2530 - categorical_accuracy: 0.1800 - val_loss: 146.4129 - val_categorical_accuracy: 0.1747\n",
      "Epoch 13/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 91.2343 - categorical_accuracy: 0.1842 - val_loss: 147.8566 - val_categorical_accuracy: 0.1624\n",
      "Epoch 14/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 87.3954 - categorical_accuracy: 0.1878 - val_loss: 148.5941 - val_categorical_accuracy: 0.1788\n",
      "Epoch 15/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 83.8904 - categorical_accuracy: 0.1819 - val_loss: 150.6856 - val_categorical_accuracy: 0.1720\n",
      "Epoch 16/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 80.6694 - categorical_accuracy: 0.1890 - val_loss: 151.9199 - val_categorical_accuracy: 0.1811\n",
      "Epoch 17/20\n",
      "6048/6048 [==============================] - 21s 4ms/step - loss: 77.5849 - categorical_accuracy: 0.1858 - val_loss: 155.2177 - val_categorical_accuracy: 0.1843\n",
      "Epoch 18/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 74.7226 - categorical_accuracy: 0.1859 - val_loss: 156.7942 - val_categorical_accuracy: 0.1808\n",
      "Epoch 19/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 72.0308 - categorical_accuracy: 0.1866 - val_loss: 160.7723 - val_categorical_accuracy: 0.1699\n",
      "Epoch 20/20\n",
      "6048/6048 [==============================] - 22s 4ms/step - loss: 69.4074 - categorical_accuracy: 0.1858 - val_loss: 162.0822 - val_categorical_accuracy: 0.1792\n"
     ]
    }
   ],
   "source": [
    "f = 0.4\n",
    "r= 20\n",
    "u_prob = unig_f(prob,f)\n",
    "\n",
    "mask = np.ones((B*21,total_words))\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i][0] = 0\n",
    "mask1 = mask\n",
    "mask= tf.cast(tf.convert_to_tensor(mask1),tf.int32)\n",
    "model2_f1 = create_model2(predictors, label,d_predictors, d_label, max_sequence_len, total_words,bin_loss_unig(r,u_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6048 samples, validate on 768 samples\n",
      "Epoch 1/20\n",
      "6048/6048 [==============================] - 49s 8ms/step - loss: 299.9476 - categorical_accuracy: 0.1123 - val_loss: 227.2171 - val_categorical_accuracy: 0.1241\n",
      "Epoch 2/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 212.8693 - categorical_accuracy: 0.1197 - val_loss: 183.5989 - val_categorical_accuracy: 0.1296\n",
      "Epoch 3/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 177.1001 - categorical_accuracy: 0.1112 - val_loss: 162.4122 - val_categorical_accuracy: 0.1073\n",
      "Epoch 4/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 155.7659 - categorical_accuracy: 0.1352 - val_loss: 150.8361 - val_categorical_accuracy: 0.1505\n",
      "Epoch 5/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 140.9066 - categorical_accuracy: 0.1857 - val_loss: 143.5432 - val_categorical_accuracy: 0.2131\n",
      "Epoch 6/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 129.0934 - categorical_accuracy: 0.1971 - val_loss: 138.9963 - val_categorical_accuracy: 0.2091\n",
      "Epoch 7/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 119.4099 - categorical_accuracy: 0.2083 - val_loss: 136.0478 - val_categorical_accuracy: 0.1945\n",
      "Epoch 8/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 111.5547 - categorical_accuracy: 0.2069 - val_loss: 133.7060 - val_categorical_accuracy: 0.2063\n",
      "Epoch 9/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 104.6564 - categorical_accuracy: 0.2069 - val_loss: 132.6920 - val_categorical_accuracy: 0.2064\n",
      "Epoch 10/20\n",
      "6048/6048 [==============================] - 23s 4ms/step - loss: 98.8645 - categorical_accuracy: 0.2069 - val_loss: 131.8289 - val_categorical_accuracy: 0.2061\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "f = 0.25\n",
    "r= 20\n",
    "u_prob = unig_f(prob,f)\n",
    "\n",
    "mask = np.ones((B*21,total_words))\n",
    "for i in range(mask.shape[0]):\n",
    "    mask[i][0] = 0\n",
    "mask1 = mask\n",
    "mask= tf.cast(tf.convert_to_tensor(mask1),tf.int32)\n",
    "model2_f4 = create_model2(predictors, label,d_predictors, d_label, max_sequence_len, total_words,bin_loss_unig(r,u_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 20, total predictions: 8059\n",
      "accuracy: 0.20486412706291104\n"
     ]
    }
   ],
   "source": [
    "total,acc,err_count = evaluate(model2_f4,t_predictors,t_label)\n",
    "print(\"r = 20, total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using a Larger Context (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Implementation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 1498\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len = 37\n",
    "def dataset_preparation(data):\n",
    "\n",
    "    # basic cleanup\n",
    "    corpus = data.split(\"\\n\")\n",
    "    # tokenization\t\n",
    "    # create input sequences using list of tokens\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        t = False\n",
    "        for i in range(1, len(token_list)-1):\n",
    "            if token_list[i] == 1:\n",
    "                t = True\n",
    "            if t:\n",
    "                n_gram_sequence = token_list[:i+2]\n",
    "                input_sequences.append(n_gram_sequence)\n",
    "    # pad sequences \n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    # create predictors and label\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len, total_words\n",
    "tokenizer = Tokenizer(lower=False,filters='\\t')\n",
    "data = open('bobsue.voc.txt').read()\n",
    "corpus = data.split(\"\\n\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "print(\"total words: \",end=\"\")\n",
    "print(total_words-1)\n",
    "\n",
    "data = open('bobsue.prevsent.train.tsv').read()\n",
    "\n",
    "dev_data = open('bobsue.prevsent.dev.tsv').read()\n",
    "test_data = open('bobsue.prevsent.test.tsv').read()\n",
    "predictors, label, max_sequence_len1,total_words1 = dataset_preparation(data)\n",
    "d_predictors, d_label, max_sequence_len2,total_words2 = dataset_preparation(dev_data)\n",
    "t_predictors, t_label, t_max_sequence_len3,total_words3 = dataset_preparation(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model3(predictors, label, X_val,Y_val, max_sequence_len, total_words):\n",
    "    model = Sequential()\n",
    "    #mask_zero to neglect padding during training  \n",
    "    model.add(Embedding(total_words, 200, input_length=max_sequence_len-1))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dense(total_words))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "    model.fit(predictors, label, epochs=10, batch_size=B,validation_data=(X_val, Y_val),verbose=1, callbacks=[earlystop])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65331 samples, validate on 7957 samples\n",
      "Epoch 1/10\n",
      "65331/65331 [==============================] - 116s 2ms/step - loss: 4.2708 - categorical_accuracy: 0.2543 - val_loss: 3.7159 - val_categorical_accuracy: 0.3006\n",
      "Epoch 2/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 3.5629 - categorical_accuracy: 0.3093 - val_loss: 3.5029 - val_categorical_accuracy: 0.3221\n",
      "Epoch 3/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 3.3063 - categorical_accuracy: 0.3329 - val_loss: 3.4254 - val_categorical_accuracy: 0.3352\n",
      "Epoch 4/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 3.0932 - categorical_accuracy: 0.3660 - val_loss: 3.3528 - val_categorical_accuracy: 0.3647\n",
      "Epoch 5/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 2.8993 - categorical_accuracy: 0.3898 - val_loss: 3.3527 - val_categorical_accuracy: 0.3695\n",
      "Epoch 6/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 2.7319 - categorical_accuracy: 0.4052 - val_loss: 3.3786 - val_categorical_accuracy: 0.3695\n",
      "Epoch 7/10\n",
      "65331/65331 [==============================] - 103s 2ms/step - loss: 2.5750 - categorical_accuracy: 0.4239 - val_loss: 3.4300 - val_categorical_accuracy: 0.3695\n",
      "Epoch 8/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 2.4264 - categorical_accuracy: 0.4432 - val_loss: 3.4745 - val_categorical_accuracy: 0.3665\n",
      "Epoch 9/10\n",
      "65331/65331 [==============================] - 103s 2ms/step - loss: 2.2871 - categorical_accuracy: 0.4652 - val_loss: 3.5235 - val_categorical_accuracy: 0.3598\n",
      "Epoch 10/10\n",
      "65331/65331 [==============================] - 102s 2ms/step - loss: 2.1539 - categorical_accuracy: 0.4899 - val_loss: 3.5842 - val_categorical_accuracy: 0.3587\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_prev = create_model3(predictors, label,d_predictors, d_label, max_sequence_len, total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Error analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total predictions: 8059\n",
      "accuracy: 0.35190470281672664\n"
     ]
    }
   ],
   "source": [
    "def evaluate2(model,p ,t):\n",
    "    #Manually implement a evaluate to check test accuracym, so that we can make sure num of predictions is correct\n",
    "    total = 0 \n",
    "    k = model.predict(p)\n",
    "    k = k.argmax(axis=1)\n",
    "    m = t.argmax(axis=1)\n",
    "    correct = 0\n",
    "    err_count = {}\n",
    "    for i in range(k.shape[0]):\n",
    "            #if label is neither padding nor <s>\n",
    "            if m[i] != 0 and m[i] != 1 : \n",
    "                total+=1 \n",
    "                if k[i] == m[i]:\n",
    "                    correct+=1 \n",
    "                else: \n",
    "                    if (m[i],k[i]) in err_count:\n",
    "                        err_count[(m[i],k[i])] +=1\n",
    "                    else:\n",
    "                        err_count[(m[i],k[i])] =1\n",
    "                        \n",
    "    return total,correct/total,err_count\n",
    "\n",
    "\n",
    "total,acc,err_count = evaluate2(model_prev,t_predictors,t_label)\n",
    "print(\"total predictions: \", end=\"\")\n",
    "print(total)\n",
    "print(\"accuracy: \", end=\"\")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Top 35 Error----\n",
      "First item of pair is truth, second item is prediction\n",
      "('.', 'to') Count: 38\n",
      "('had', 'was') Count: 33\n",
      "('to', '.') Count: 32\n",
      "('and', '.') Count: 30\n",
      "('decided', 'was') Count: 28\n",
      "('He', 'Bob') Count: 27\n",
      "('for', '.') Count: 23\n",
      "('was', 'had') Count: 23\n",
      "('the', 'her') Count: 22\n",
      "('his', 'the') Count: 22\n",
      "('Sue', 'Bob') Count: 21\n",
      "('got', 'was') Count: 20\n",
      "('.', 'and') Count: 20\n",
      "('the', 'a') Count: 19\n",
      "('Her', 'She') Count: 19\n",
      "('Sue', 'She') Count: 18\n",
      "('Bob', 'He') Count: 18\n",
      "('in', '.') Count: 18\n",
      "('!', '.') Count: 17\n",
      "(',', '.') Count: 17\n",
      "('a', 'to') Count: 17\n",
      "('he', 'to') Count: 17\n",
      "('her', 'a') Count: 16\n",
      "('for', 'to') Count: 16\n",
      "('the', 'his') Count: 16\n",
      "(\"'s\", 'was') Count: 16\n",
      "('went', 'was') Count: 16\n",
      "('.', 'for') Count: 15\n",
      "('She', 'Sue') Count: 14\n",
      "('Bob', 'Sue') Count: 14\n",
      "('and', 'to') Count: 14\n",
      "('her', 'the') Count: 13\n",
      "('His', 'He') Count: 13\n",
      "('on', '.') Count: 13\n",
      "('His', 'Bob') Count: 13\n"
     ]
    }
   ],
   "source": [
    "sort_err = sorted(err_count.items(),key=lambda x:x[1],reverse=True)\n",
    "def translate(a):\n",
    "    x,y = a \n",
    "    return (tokenizer.index_word[x],tokenizer.index_word[y])\n",
    "top35 = sort_err[0:35]\n",
    "\n",
    "print(\"----Top 35 Error----\")\n",
    "print(\"First item of pair is truth, second item is prediction\")\n",
    "\n",
    "for t,cnt in top35:\n",
    "    true, pred = translate(t)\n",
    "    print((true,pred),end=\" \")\n",
    "    print(\"Count: \",end=\"\")\n",
    "    print(cnt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
