{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import numpy as np \n",
    "from random import shuffle\n",
    "from time import time \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised Parameter Estimation for HMMs (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open('en_ewt.train',encoding=\"utf8\").read()\n",
    "dev = open('en_ewt.dev',encoding=\"utf8\").read()\n",
    "corpus = list(map(lambda x: list(map(lambda y: y.split(\"\\t\"), x.split(\"\\n\"))),train.split(\"\\n\\n\")))\n",
    "corpus = corpus[:-1]\n",
    "\n",
    "word_index = {}\n",
    "index_word = {}\n",
    "word_index['<s>']= 0 \n",
    "word_index['</s>']= 1\n",
    "index_word[0] = '<s>'\n",
    "index_word[1] = '</s>'\n",
    "\n",
    "tag_index = {}\n",
    "index_tag = {}\n",
    "tag_index['<s>']= 0 \n",
    "tag_index['</s>']= 1\n",
    "index_tag[0] = '<s>'\n",
    "index_tag[1] = '</s>'\n",
    "\n",
    "m = 2 \n",
    "k = 2\n",
    "for sent in corpus:\n",
    "    for w, t in sent:\n",
    "        if t not in tag_index:\n",
    "            tag_index[t] = k \n",
    "            index_tag[k] = t\n",
    "            k+= 1 \n",
    "        if w not in word_index:\n",
    "            word_index[w] = m \n",
    "            index_word[m] = w\n",
    "            m += 1 \n",
    "        \n",
    "            \n",
    "num_words = len(word_index)\n",
    "e_mat = np.zeros((52,num_words))\n",
    "t_mat = np.zeros((52,52))\n",
    "\n",
    "for sent in corpus:\n",
    "    prev = '<s>'\n",
    "    for w, t in sent:\n",
    "        i_prev,i_cur,i_word = tag_index[prev],tag_index[t],word_index[w]\n",
    "        t_mat[i_prev][i_cur] +=  1\n",
    "        e_mat[i_cur][i_word] += 1\n",
    "        \n",
    "        prev = t \n",
    "    \n",
    "    t = '</s>'\n",
    "    i_prev,i_cur = tag_index[prev],tag_index[t]\n",
    "    t_mat[i_prev][i_cur] = t_mat[i_prev][i_cur]  + 1\n",
    "    \n",
    "l_t = 0.1 \n",
    "l_e = 0.001\n",
    "\n",
    "t_mat  = t_mat + l_t\n",
    "e_mat = e_mat + l_e \n",
    "\n",
    "t_mat[0][1] = 0 \n",
    "t_mat[:,0] = 0\n",
    "\n",
    "\n",
    "row_sums = t_mat.sum(axis=1)\n",
    "t_mat = t_mat / row_sums[:, np.newaxis]\n",
    "t_mat[1] = 0\n",
    "\n",
    "row_sums = e_mat.sum(axis=1)\n",
    "e_mat = e_mat / row_sums[:, np.newaxis]\n",
    "e_mat[0:2] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Verify implementation correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----5 tags with the highest probability of following <s>----\n",
      "probability: 0.22450589735415996,tag: PRP\n",
      "probability: 0.11596270321963656,tag: NNP\n",
      "probability: 0.11237647433853996,tag: DT\n",
      "probability: 0.0781080650302837,tag: IN\n",
      "probability: 0.06567580490914886,tag: RB\n",
      "----10 most probable words emitted by the adjective tag('JJ')----\n",
      "Probability: 0.023068966829187507,word: other\n",
      "Probability: 0.021605642303920113,word: good\n",
      "Probability: 0.016785279161862805,word: new\n",
      "Probability: 0.013686474284825965,word: many\n",
      "Probability: 0.013686474284825965,word: great\n",
      "Probability: 0.011362370627048334,word: same\n",
      "Probability: 0.009554734448776844,word: sure\n",
      "Probability: 0.009210422795772751,word: last\n",
      "Probability: 0.00895218905601968,word: few\n",
      "Probability: 0.00843572157651354,word: little\n"
     ]
    }
   ],
   "source": [
    "p = list(zip(t_mat[0][t_mat[0].argsort()[-5:]],t_mat[0].argsort()[-5:])) \n",
    "\n",
    "print(\"----5 tags with the highest probability of following <s>----\")\n",
    "\n",
    "for score,id_ in p[::-1]:\n",
    "    print(\"probability: \",end=\"\")\n",
    "    print(score,end=\",\")\n",
    "    print(\"tag: {}\".format(index_tag[id_]))\n",
    "\n",
    "print(\"----10 most probable words emitted by the adjective tag('JJ')----\")\n",
    "\n",
    "p = list(zip(e_mat[tag_index['JJ']][e_mat[tag_index['JJ']].argsort()[-10:]],\n",
    "            e_mat[tag_index['JJ']].argsort()[-10:]))\n",
    "for score,id_ in p[::-1]:\n",
    "    print(\"Probability: \",end=\"\")\n",
    "    print(score,end=\",\")\n",
    "    print(\"word: {}\".format(index_word[id_]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preliminaries for Inference with HMMs (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Log-probability calculation (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(data):\n",
    "    corpus = list(map(lambda x: list(map(lambda y: y.split(\"\\t\"), x.split(\"\\n\"))),data.split(\"\\n\\n\")))\n",
    "    sent = []\n",
    "    tags = []\n",
    "    for i in corpus: \n",
    "        length = 0\n",
    "        ss = np.zeros(len(i))\n",
    "        tt = np.zeros(len(i))\n",
    "        for j in range(len(i)):\n",
    "            if len(i[j]) ==  2:\n",
    "                ss[j] = word_index[i[j][0]]\n",
    "                tt[j] = tag_index[i[j][1]]\n",
    "                length += 1\n",
    "                \n",
    "        if length != 0:\n",
    "            sent.append(ss.astype(np.int))\n",
    "            tags.append(tt.astype(np.int))\n",
    "    return sent,tags\n",
    "\n",
    "def log_prob(x,y):\n",
    "    res = 0\n",
    "    for i in range(len(x)-1):\n",
    "        i_word,i_tag = x[i],y[i]\n",
    "        next_tag = y[i+1]\n",
    "        res += np.log(e_mat[i_tag][i_word]) + np.log(t_mat[i_tag][next_tag])\n",
    "    res += np.log(t_mat[0][y[0]]) \n",
    "    res += np.log(t_mat[y[-1]][1]) + + np.log(e_mat[y[-1]][x[-1]])   \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-169936.4097817666\n"
     ]
    }
   ],
   "source": [
    "total_prob  = 0 \n",
    "dev_x, dev_y = preprocess(dev)\n",
    "for i in range(len(dev_x)):\n",
    "    total_prob += log_prob(dev_x[i],dev_y[i])\n",
    "print(total_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Local predictor baseline (3 points): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapse in sec:  0.03206777572631836\n",
      "accuracy:  0.7988866799204771\n",
      "log prob:  -186408.17332565217\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def local_predict(sent):\n",
    "    tag = e_mat[:,sent].argmax(axis=0)\n",
    "    return tag\n",
    "\n",
    "def evaluate(predict,truth):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(predict)):\n",
    "        correct += (predict[i] == truth[i]).sum()\n",
    "        total += truth[i].shape[0] \n",
    "    return total,correct\n",
    "\n",
    "s = time()\n",
    "prediction = []\n",
    "for i in range(2002):\n",
    "    prediction.append(local_predict(dev_x[i]))\n",
    "    \n",
    "print(\"time_elapse in sec: \",time()-s)\n",
    "\n",
    "total,correct = evaluate(prediction,dev_y)\n",
    "\n",
    "print(\"accuracy: \", correct/total)\n",
    "\n",
    "total_prob=0\n",
    "for i in range(len(dev_x)):\n",
    "    total_prob += log_prob(dev_x[i],prediction[i])\n",
    "print(\"log prob: \", total_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Left-to-Right Algorithms (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapse in sec:  0.3826887607574463\n",
      "accuracy:  0.8740357852882704\n",
      "log prob:  -166188.90291524684\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def greedy_leftright(sent):\n",
    "    tag = np.zeros(sent.shape[0]).astype(np.int)\n",
    "    prev = 0    \n",
    "    for i in range(sent.shape[0]-1):\n",
    "        \n",
    "        tag[i] = int((e_mat[:,sent[i]]* t_mat[prev]).argmax())\n",
    "        prev = tag[i]\n",
    "    tag[-1] = (e_mat[:,sent[-1]]* t_mat[prev] * t_mat[:,1]).argmax()\n",
    "    \n",
    "    return tag\n",
    "\n",
    "def evaluate(predict,truth):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(predict)):\n",
    "        correct += (predict[i] == truth[i]).sum()\n",
    "        total += truth[i].shape[0] \n",
    "    return total,correct\n",
    "\n",
    "s = time()\n",
    "prediction = []\n",
    "for i in range(2002):\n",
    "    prediction.append(greedy_leftright(dev_x[i]))\n",
    "    \n",
    "print(\"time_elapse in sec: \",time()-s)\n",
    "\n",
    "total,correct = evaluate(prediction,dev_y)\n",
    "\n",
    "print(\"accuracy: \", correct/total)\n",
    "\n",
    "total_prob=0\n",
    "for i in range(len(dev_x)):\n",
    "    total_prob += log_prob(dev_x[i],prediction[i])\n",
    "print(\"log prob: \", total_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Greedy Right-to-Left Algorithms (10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapse in sec:  0.21828842163085938\n",
      "accuracy:  0.8001590457256461\n",
      "log prob:  -176754.99936669567\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def greedy_rightleft(sent):\n",
    "    tag = np.zeros(sent.shape[0]).astype(np.int)\n",
    "    next_ = 1   \n",
    "    for i in range(1,sent.shape[0]):        \n",
    "        tag[-i] = (e_mat[:,sent[-i]]* t_mat[:,next_]).argmax()\n",
    "        next_ = tag[-i]\n",
    "    tag[0] = (e_mat[:,sent[0]]* t_mat[:,next_] * t_mat[0]).argmax()\n",
    "    \n",
    "    return tag\n",
    "\n",
    "def evaluate(predict,truth):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(predict)):\n",
    "        correct += (predict[i] == truth[i]).sum()\n",
    "        total += truth[i].shape[0] \n",
    "    return total,correct\n",
    "\n",
    "s = time()\n",
    "prediction = []\n",
    "for i in range(2002):\n",
    "    prediction.append(greedy_rightleft(dev_x[i]))\n",
    "    \n",
    "print(\"time_elapse in sec: \",time()-s)\n",
    "\n",
    "total,correct = evaluate(prediction,dev_y)\n",
    "\n",
    "print(\"accuracy: \", correct/total)\n",
    "\n",
    "total_prob=0\n",
    "for i in range(len(dev_x)):\n",
    "    total_prob += log_prob(dev_x[i],prediction[i])\n",
    "print(\"log prob: \", total_prob)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results. In your discussion, consider the following points. What do you\n",
    "notice about the performance (accuracy and log-probability) of this algorithm compared to the\n",
    "local and left-to-right algorithms? Why do you think you see these trends? What changes might\n",
    "you make to improve the accuracy of greedy right-to-left algorithms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Interestingly, we see log prob shows LF (left-to-right) has higher log prob than RF (right-to-left), and RF has higher log prob than LC(local). However, the accuracy doesn't quite match with this difference, because RF only outforms LC by a very small margin while there's huge improvement from LF to RF. \n",
    "\n",
    "I think this is because of model error. One aspect is that the model  might predict the last words badly, so later predictions of RF which are contigent upon the previous predictions also become bad. (While LF can better predict the left starting word). This may be because words on the left of a sentence carry more info than on the right of a sentence.\n",
    "\n",
    "Furthermore, when we train the model, we learn the probability from left to right, but the conditional probability of P(A|B) is different from P(B|A), so when we use the model to predict from right to left (say from B to A), we're actually using P(A|B), which might not give us the most possible left word given the right word B. \n",
    "\n",
    "So one change might be to train the model by learning the conditional probability of the left word given the right word (i.e. right to left instead of left to right), and then run the right to left greedy algorithm based on this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exact Inference with Viterbi (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_elapse in sec:  1.3345210552215576\n",
      "accuracy:  0.8941153081510934\n",
      "log prob:  -163206.91122073226\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "def viterbi(sent):\n",
    "    dp = np.zeros(t_mat.shape[0])\n",
    "    dp = e_mat[:,sent[0]] * t_mat[0]\n",
    "    history = np.zeros((t_mat.shape[0],len(sent)-1))\n",
    "    tag = np.zeros(len(sent)).astype(np.int)\n",
    "    \n",
    "    for i in range(1,sent.shape[0]):  \n",
    "        temp = dp*t_mat.T\n",
    "        history[:,i-1] = temp.argmax(axis=1)\n",
    "        dp = e_mat[:,sent[i]] * (temp.max(axis=1)) \n",
    "        \n",
    "    end = (t_mat[:,1] * dp).argmax()\n",
    "    tag[-1] = end\n",
    "    for i in range(1,sent.shape[0]):\n",
    "        tag[-i-1] = history[end][-i] \n",
    "        end = tag[-i-1]\n",
    "    \n",
    "    return tag\n",
    "\n",
    "def evaluate(predict,truth):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(predict)):\n",
    "        correct += (predict[i] == truth[i]).sum()\n",
    "        total += truth[i].shape[0] \n",
    "    return total,correct\n",
    "\n",
    "s = time()\n",
    "prediction = []\n",
    "for i in range(2002):\n",
    "    prediction.append(viterbi(dev_x[i]))\n",
    "    \n",
    "print(\"time_elapse in sec: \",time()-s)\n",
    "\n",
    "total,correct = evaluate(prediction,dev_y)\n",
    "\n",
    "print(\"accuracy: \", correct/total)\n",
    "\n",
    "total_prob=0\n",
    "for i in range(len(dev_x)):\n",
    "    total_prob += log_prob(dev_x[i],prediction[i])\n",
    "print(\"log prob: \", total_prob)\n",
    "\n",
    "\n",
    "##(b) see latex response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  Extra Credit: Beam Search for HMMs (5 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
